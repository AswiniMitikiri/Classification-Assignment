{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309c64a6-0cc7-4d2e-8ec6-fbc28455fc3f",
   "metadata": {},
   "source": [
    "## 1. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10fe43da-1208-4bc1-9847-478969f684d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b542f7c-ed78-44da-add1-8c41b2eaca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "df = load_breast_cancer()\n",
    "X = pd.DataFrame(df.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bb66e3c-3876-4668-a7f1-f5a5f18bb9a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a5e1d2-aa69-4bba-ac23-f710fce93e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "561d13cb-6672-4d81-bbcf-f4a5bf69ecdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2f81bf1-ed2d-4440-a72a-bf6b00222803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea4dde0c-c953-44d9-9c88-d061f3e23b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d643e4c-0c24-4eb1-a47f-676ad05574ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984971ba-f85c-43b2-ac85-03302b28f9d3",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "No missing values found.\n",
    "   \n",
    "StandardScaler is used to normalize the feature values.\n",
    "  \n",
    "Data is split 80/20 for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da0f75-bcd4-47ac-9b53-992991f0ee83",
   "metadata": {},
   "source": [
    "# 2. Classification Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862209d-c81e-44bc-958a-24cc19c18ea2",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce338446-bcde-49ea-94e6-5f34b836b3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_pred))\n",
    "print(classification_report(y_test, lr_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "30bba247-4c4c-43c2-a874-01e65df88349",
   "metadata": {},
   "source": [
    " 1. Logistic Regression\n",
    "üîπ How it works:\n",
    "Logistic Regression is a linear model used for binary classification. It calculates the probability that a data point belongs to a class using the sigmoid function, which maps any real-valued number into a value between 0 and 1.\n",
    "\n",
    "üîπ Why it's suitable:\n",
    "The breast cancer dataset is binary (malignant or benign), making logistic regression a natural choice.\n",
    "\n",
    "It's fast, interpretable, and performs well when the relationship between features and target is linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773abc7f-345d-42f9-9acd-f85dd6d78925",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4695fd24-1c6c-4ff9-8681-e310a92c21e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9385964912280702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.91      0.92        43\n",
      "      benign       0.94      0.96      0.95        71\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
    "print(classification_report(y_test, dt_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d63a0f3-9d7c-4d39-8e73-08ecedb43d10",
   "metadata": {},
   "source": [
    " 2. Decision Tree Classifier\n",
    "üîπ How it works:\n",
    "A Decision Tree splits the data into branches based on feature values using metrics like Gini impurity or entropy. Each node in the tree represents a decision point based on a feature, eventually leading to a prediction at a leaf node.\n",
    "\n",
    "üîπ Why it's suitable:\n",
    "Handles non-linear relationships well.\n",
    "\n",
    "Provides visual and interpretable decision-making, useful in medical datasets.\n",
    "\n",
    "Doesn‚Äôt require feature scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d32d70-34d8-4a13-8ad0-b55ddacbb695",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c8a2ded-deaf-46cc-9b12-c3e95e8d3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.93      0.95        43\n",
      "      benign       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_pred))\n",
    "print(classification_report(y_test, rf_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859438fc-51b8-45a3-8181-243301ed352c",
   "metadata": {},
   "source": [
    "3. Random Forest Classifier\n",
    "üîπ How it works:\n",
    "Random Forest is an ensemble learning method that builds multiple decision trees on different subsets of the dataset and averages their results to make a final prediction, reducing overfitting.\n",
    "\n",
    "üîπ Why it's suitable:\n",
    "Offers high accuracy and robustness.\n",
    "\n",
    "Works well even if some features are less informative.\n",
    "\n",
    "Excellent for handling complex and noisy data like medical records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed4ada-8b58-4130-b0b7-0a43251d08d5",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1b327d9-9617-4625-9560-3186e3ecc12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9736842105263158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(classification_report(y_test, svm_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aafb820e-f50b-43a3-9fbd-29cda90d7322",
   "metadata": {},
   "source": [
    "4. Support Vector Machine (SVM)\n",
    "üîπ How it works:\n",
    "SVM finds the optimal hyperplane that separates data points of different classes with the maximum margin. It can also handle non-linear classification using kernel tricks (like RBF).\n",
    "\n",
    "üîπ Why it's suitable:\n",
    "Effective in high-dimensional spaces like this dataset (30 features).\n",
    "\n",
    "Works well when there is a clear margin of separation between classes.\n",
    "\n",
    "Performs well even with a limited number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e8baf0-2d2a-4689-8a25-659b2770bad5",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a9ba144-d892-459d-b6e1-c5f40c240a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.93      0.93      0.93        43\n",
      "      benign       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "print(\"k-NN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
    "print(classification_report(y_test, knn_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e41cbb8d-78d9-43cb-97e6-b27f63e55729",
   "metadata": {},
   "source": [
    "5. k-Nearest Neighbors (k-NN)\n",
    "üîπ How it works:\n",
    "k-NN is a lazy learning algorithm that makes predictions by looking at the ‚Äòk‚Äô closest data points in the training set and assigning the most common class among them.\n",
    "\n",
    "üîπ Why it's suitable:\n",
    "Simple to understand and implement.\n",
    "\n",
    "Can perform well with proper scaling and tuning of ‚Äòk‚Äô.\n",
    "\n",
    "Suitable for this dataset due to balanced classes and relatively low feature count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e43a278-8404-42fd-a04b-bb6b8cae0bad",
   "metadata": {},
   "source": [
    "#  3. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb798909-cb7b-4335-ac96-c47477e28357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison:\n",
      "                  Model  Accuracy\n",
      "0  Logistic Regression  0.973684\n",
      "1        Decision Tree  0.938596\n",
      "2        Random Forest  0.964912\n",
      "3                  SVM  0.973684\n",
      "4                 k-NN  0.947368\n",
      "\n",
      "‚úÖ Best Model: Logistic Regression with accuracy: 0.9737\n",
      "‚ùå Worst Model: Decision Tree with accuracy: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# Collecting model performances\n",
    "results = {\n",
    "    \"Logistic Regression\": accuracy_score(y_test, lr_pred),\n",
    "    \"Decision Tree\": accuracy_score(y_test, dt_pred),\n",
    "    \"Random Forest\": accuracy_score(y_test, rf_pred),\n",
    "    \"SVM\": accuracy_score(y_test, svm_pred),\n",
    "    \"k-NN\": accuracy_score(y_test, knn_pred)\n",
    "}\n",
    "\n",
    "# Creating a DataFrame for comparison\n",
    "results_df = pd.DataFrame(list(results.items()), columns=[\"Model\", \"Accuracy\"])\n",
    "\n",
    "# Display results\n",
    "print(\"Model Comparison:\\n\", results_df)\n",
    "\n",
    "# Best and Worst model\n",
    "best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "worst_model = results_df.loc[results_df['Accuracy'].idxmin()]\n",
    "\n",
    "print(f\"\\n‚úÖ Best Model: {best_model['Model']} with accuracy: {best_model['Accuracy']:.4f}\")\n",
    "print(f\"‚ùå Worst Model: {worst_model['Model']} with accuracy: {worst_model['Accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0e564-7beb-4797-ace7-3e7fecff8f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
